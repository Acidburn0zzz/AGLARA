<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0" xml:id="platform" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <title>Platform selection</title>

  <section>
    <title>Gentoo Linux</title>

    <para>Within the reference architecture, we standardize on Gentoo Linux.
    Standardization on a single platform is needed to keep costs sufficiently
    low, but also offers the advantage that you can use solutions specific for
    this platform, rather than having to look for solutions that must support
    a multitude of platforms. Of course, the choice of picking Gentoo Linux
    here might seem weird - why not CentOS (as that has a possible commercial
    backing towards RedHat Enterprise Linux when needed)?</para>

    <itemizedlist>
      <listitem>
        <para>First of all - I'm a Gentoo Linux developer. Its the
        distribution I know the best.</para>

        <para>But in light of our fictional company, it might also be because
        its current (fictional) engineers are all Gentoo Linux developers, or
        because it has ties with regional Gentoo Linux supporting services. In
        light of many organizations, when there is choice between Linux
        distributions, one thing to consider is which distribution your
        engineers are most likely to work with. I know, asking them will
        probably result in some heavy fighting to see which distribution is
        best (perhaps you can use the <link
        xlink:href="https://en.wikipedia.org/wiki/Condorcet_method">Condorset
        method</link> to find the best selection), but picking a distribution
        your engineers are less eager to support will result in bad
        administration anyhow.</para>
      </listitem>

      <listitem>
        <para>The reason to use CentOS (RHEL) could be to have certified
        hosting of certain products which are only supported on RHEL (or
        similar). However, because we will only use free software solutions,
        this requirement is not valid in our case. But it is understandable
        that companies that do run propriatary software choose a distribution
        that is supported by their vendors.</para>
      </listitem>

      <listitem>
        <para>Gentoo Linux offers a fairly flexible approach on supported
        features. Thanks to a good balance of USE flags, we can install
        servers and services that offer just those services we need, without
        any additional dependencies or features that we will have to disable
        (in order to secure the services) anyhow. This leads to somewhat
        better performance, but also to a saving in storage requirements,
        patching frequency, etc. Gentoo is also quite fast in adopting new
        technologies, which might help the business stand out against the
        other competitors.</para>
      </listitem>

      <listitem>
        <para>Gentoo uses rolling upgrades. That might not seem like a good
        way in enterprises, but trust me - it is. If an organization is doing
        things right, it is already distributing and rolling out patches and
        minor upgrades regularly. With Gentoo, this process is a bit more
        intrusive (as it might contain larger changes as well) but because the
        administrators are used to it, it is very much under control. As a
        result, whereas other organizations have to schedule large (expensive
        and time-consuming) upgrades every 3 to 5 years, Gentoo just moves
        along...</para>
      </listitem>

      <listitem>
        <para>Gentoo has a subproject called Gentoo Hardened who strives to
        provide security-improving patches on the base system. This project
        has always been a fore-runner in security mitigation
        strategies.</para>
      </listitem>
    </itemizedlist>

    <para>Of course, because this book is called "A Gentoo Linux Advanced
    Reference Architecture", it would be weird to have it talk about another
    distribution, wouldn't it?</para>

    <para>Now, the selection of Gentoo Linux also has a few challenges up its
    sleeve.</para>

    <itemizedlist>
      <listitem>
        <para>Gentoo Linux is primarily a source-based distribution, which is
        frequently frowned upon in the enterprise market. Weirdly enough, they
        don't find it strange that their development and operational teams
        keep on building frameworks and tools themselves because of lack of
        good tools. This is exactly where Gentoo Linux outshines the others:
        it offers many tools out-of-the-box to support every possible
        requirement.</para>

        <para>To reduce the impact of its source-only stigma, we will be using
        build servers and binhost support for improved manageability.</para>
      </listitem>

      <listitem>
        <para>Because of its source-based nature, it also provides all the
        tools for malicious users to build exploits on the server
        itself.</para>

        <para>In my opinion, it is fairly easy to hide the compiler or at
        least have some group-based access control on it. But regardless of
        that - the moment a malicious user has (shell) access to your system,
        you're screwed anyhow. It is fairly easy to transfer files (even full
        applications) towards the system then.</para>

        <para>To reduce possible impact here, we will be using a Mandatory
        Access Control system which isolates processes and even users very
        tightly.</para>
      </listitem>
    </itemizedlist>

    <para>We will standardize on the x86_64 architecture (or in Gentoo's
    terms, amd64), partially because it is the widest known in the Gentoo
    Linux development community, but also because its hardware is widely
    available and sufficiently cheap. It is also a processor architecture that
    is constantly evolving and has many vendors working on it (less
    monopolizing strategies) which makes it a better platform for consumers in
    my opinion.</para>

    <para>That being said, we'll also use the no-multilib approach in Gentoo
    Linux. Systems need to be fully x86_64 driven, partially for
    standardization as well, but also to make debugging easier. The fewer
    special cases you need to think about, the faster you can resolve
    problems. Generally though, this gives little (to no) additinoal advantage
    towards a multilib profile. But as this is a reference architecture, I'll
    stick with this.</para>

    <section>
      <title>Gentoo Hardened</title>

      <para>To increase security of the deployments, all systems will use a
      Gentoo Hardened deployment. Within the Gentoo Linux community, Gentoo
      Hardened is a project that oversees the research, implementation and
      maintenance of security-oriented projects in Gentoo Linux. It focuses on
      delivering viable security strategies for high stability production
      environments and is therefor absolutely suitable for this reference
      architecture.</para>

      <para>Within our scope, we will implement all services on a Gentoo
      Hardened deployment with the following security measures in
      place:</para>

      <itemizedlist>
        <listitem>
          <para>PaX</para>
        </listitem>

        <listitem>
          <para>PIE/PIC/SSP</para>
        </listitem>

        <listitem>
          <para>SELinux as MAC</para>
        </listitem>

        <listitem>
          <para>grSecurity kernel improvements</para>
        </listitem>
      </itemizedlist>

      <para>The installation of a Gentoo Hardened system is similar to a
      regular Gentoo Linux one. You can find all necessary information on the
      Gentoo Hardened project page. Later, we'll use images of a (succesful)
      installation for seeding new servers and systems.</para>

      <section>
        <title>PaX</title>

        <para>The PaX<indexterm>
            <primary>PaX</primary>
          </indexterm> project (part of grSecurity) aims to update the Linux
        kernel with <link
        xlink:href="http://pax.grsecurity.net/docs/pax.txt">defense
        mechanisms</link> against exploitation of software bugs that allow an
        attacker access to the software's address space (memory). By
        exploiting this access, a malicious user could introduce or execute
        arbitrary code, execute existing code without the applications'
        intended behavior, or with different data than expected.</para>

        <para>One of the defence mechanisms introduced is NOEXEC<indexterm>
            <primary>NOEXEC</primary>
          </indexterm>. With this enabled, memory pages of an application
        cannot be marked writeable and executable. So either a memory page
        contains application code, but cannot be modified (kernel enforced),
        or it contains data and cannot be executed (kernel enforced). The
        enforcement methods used are beyond the scope of this book, but are
        described <link
        xlink:href="http://pax.grsecurity.net/docs/noexec.txt">online</link>.
        Enforcing NOEXEC does have potential consequences: some applications
        do not work when PaX enforces this behavior. Because of this, PaX
        allows administrators to toggle the enforcement on a per-binary basis.
        For more information about this, see the Hardened Gentoo PaX
        Quickstart document (see resources at the end of this chapter). Note
        that this also requires PIE/PIC built code (see later).</para>

        <para>Another mechanism used is ASLR<indexterm>
            <primary>ASLR</primary>
          </indexterm>, or Address Space Layout Randomization. This thwarts
        attacks that need advance knowledge of addresses (for instance through
        observation of previous runs). With ASLR enabled, the address space is
        randomized for each application, which makes it much more difficult to
        guess where a certain code (or data) portion is loaded, and as such
        attacks will be much more difficult to execute succesfully. This
        requires the code to be PIE built.</para>

        <para>To enable PaX, you will need to install the hardened-sources
        kernel in Gentoo Linux and configure it according to the instructions
        found on the Hardened Gentoo PaX Quickstart document. You should also
        install <command>paxctl</command><indexterm>
            <primary>paxctl</primary>
          </indexterm>.</para>

        <programlisting># <command>emerge hardened-sources</command>
# <command>emerge paxctl</command></programlisting>
      </section>

      <section>
        <title>PIE/PIC/SSP</title>

        <para>The given abbreviations describe how source code is built into
        binary, executable code.</para>

        <para>PIC<indexterm>
            <primary>PIC</primary>
          </indexterm> (Position Independent Code) is used for shared
        libraries to support the fact that they are loaded in memory
        dynamically (and without prior knowledge to the addresses). Whereas
        older methods use load-time relocation (where address pointers are all
        rewritten the moment the code is loaded in memory), PIC uses a higher
        abstraction of indirection towards data and function references. By
        building shared objects with PIC, relocations in the text segment in
        memory (which contains the application code) are not needed anymore.
        As such, these pages can be marked as non-writeable.</para>

        <para>To find out if you have libraries that still support text
        relocations<indexterm>
            <primary>text relocation</primary>
          </indexterm>, you can install the pax-utils package and scan your
        libraries for text relocations:</para>

        <programlisting># <command>emerge pax-utils</command>
$ <command>scanelf -lpqt</command>
TEXTREL  /opt/Citrix/ICAClient/libctxssl.so</programlisting>

        <para>In the above example, the libctxssl.so file is not built with
        PIC and as such could be more vulnerable to attacks as its
        code-containing memory pages might not be marked as
        non-writeable.</para>

        <para>With PIE<indexterm>
            <primary>PIE</primary>
          </indexterm> (Position Independent Executables) enabled, executables
        are built in a fashion similar to shared objects: their base address
        can be relocated and as such, PaX' ASLR method can be put in effect to
        randomize the address in use. An application binary that is PIE-built
        will show up as a shared object file rather than an executable file
        when checking its ELF header</para>

        <programlisting>$ <command>readelf -h /bin/ls | grep Type</command>
  Type:            DYN (Shared object file)

$ <command>readelf -h /opt/Citrix/ICAClient/wfcmgr.bin | grep Type</command>
  Type:            EXEC (Executable file)</programlisting>

        <para>SSP<indexterm>
            <primary>SSP</primary>
          </indexterm> finally stands for Stack Smashing Protection. Its
        purpose is to add in additional buffers after memory allocations (for
        variables and such) which contain a cryptographic marker (often called
        the canary). When an overflow occurs, this marker is also overwritten
        (after all, that's how overflows work). When a function would return,
        this marker is first checked to see if it is still valid. If not, then
        an overflow has occurred and the application is stopped
        abruptly.</para>
      </section>

      <section>
        <title>Checking PaX and PIE/PIC/SSP results</title>

        <para>If you want to verify the state of your system after applying
        the security measures identified earlier, install paxtest and run it.
        The application supports two modes: kiddie and blackhat. The blackhat
        test gives the worst-case scenario back whereas the kiddie-mode runs
        tests that are more like the ones script-kiddies would run. The
        paxtest application simulates certain attacks and presents plausible
        results to the reader.</para>

        <para>A full explanation on the tests ran can be found in the
        <filename>/usr/share/doc/paxtest-*/README</filename> file.</para>

        <programlisting># <command>emerge paxtest</command>
# <command>paxtest blackhat</command>

PaXtest - Copyright(c) 2003,2004 by Peter Busser &lt;peter@adamantix.org&gt;
Released under the GNU Public Licence version 2 or later

Writing output to paxtest.log
It may take a while for the tests to complete
Test results:
PaXtest - Copyright(c) 2003,2004 by Peter Busser &lt;peter@adamantix.org&gt;
Released under the GNU Public Licence version 2 or later

Mode: blackhat
Linux hpl 3.1.6-hardened #1 SMP PREEMPT Tue Dec 27 13:49:05 CET 2011 x86_64 Intel(R) Core(TM) i5 CPU M 430 @ 2.27GHz GenuineIntel GNU/Linux

Executable anonymous mapping             : Killed
Executable bss                           : Killed
Executable data                          : Killed
Executable heap                          : Killed
Executable stack                         : Killed
Executable shared library bss            : Killed
Executable shared library data           : Killed
...
Writable text segments                   : Killed
</programlisting>

        <para>These tests will try to write data and then execute it. The
        tests do this in different locations to verify if the memory
        protection measures are working. Killed means that it works as the
        attempt is stopped.</para>

        <programlisting>Executable anonymous mapping (mprotect)  : Killed
Executable bss (mprotect)                : Killed
Executable data (mprotect)               : Killed
Executable heap (mprotect)               : Killed
Executable stack (mprotect)              : Killed
Executable shared library bss (mprotect) : Killed
Executable shared library data (mprotect): Killed
</programlisting>

        <para>These are virtually the same tests as before, but now the
        application first tries to reset or change the protection bits on the
        pages using mprotect.</para>

        <programlisting>Anonymous mapping randomisation test     : 33 bits (guessed)
Heap randomisation test (ET_EXEC)        : 13 bits (guessed)
Heap randomisation test (PIE)            : 40 bits (guessed)
Main executable randomisation (ET_EXEC)  : No randomisation
Main executable randomisation (PIE)      : 32 bits (guessed)
Shared library randomisation test        : 33 bits (guessed)
Stack randomisation test (SEGMEXEC)      : 40 bits (guessed)
Stack randomisation test (PAGEEXEC)      : 40 bits (guessed)
</programlisting>

        <para>The randomisation tests try to find out which level of
        randomisation is put in place. Although randomisation by itself does
        not offer protection, it obscures the view malicious users have on the
        memory structures. The higher the randomisation, the better. On Gentoo
        Hardened, (almost) all binaries are PIE.</para>

        <programlisting>Return to function (strcpy)              : paxtest: return address contains a NULL byte.
Return to function (memcpy)              : Vulnerable
Return to function (strcpy, PIE)         : paxtest: return address contains a NULL byte.
Return to function (memcpy, PIE)         : Vulnerable
</programlisting>

        <para>These types of attacks are very difficult to thwart by kernel
        protection measures only. The author of the paxtest application has
        put those in because he can, even though he knows PaX does not protect
        against them. In effect, he tries to show users that PaX is not an
        all-safe method and that additional security layers are still
        important.</para>
      </section>

      <section>
        <title>SELinux as MAC</title>

        <para>With a MAC<indexterm>
            <primary>MAC</primary>
          </indexterm> (Mandatory Access Control<indexterm>
            <primary>Mandatory Access Control</primary>
          </indexterm>), the system administrator can control which accesses
        are allowed and which not, and can enforce that the user cannot
        override this. Regular access patterns in Linux are discretionary, so
        the user can define this himself. In this book, we will use
        SELinux<indexterm>
            <primary>SELinux</primary>
          </indexterm> as the MAC system. Another supported MAC in Gentoo
        Hardened is grSecurity's RBAC model.</para>

        <para>Installing and configuring Hardened Gentoo with SELinux is
        described in the Gentoo SELinux handbook. It is seriously recommended
        to read through this resource a few times, as SELinux is not just
        about enabling a feature - it is a change in the security model and
        requires experience with it.</para>

        <para>We will use the SELinux strict policy (so no unconfined domains)
        for regular services, or MCS (without unconfined domains) when we want
        to use the multi-tenancy support.</para>

        <programlisting>$ <command>id -Z</command>
staff_u:staff_r:staff_t

# <command>sestatus</command>
SELinux status:                 enabled
SELinuxfs mount:                /selinux
SELinux root directory:         /etc/selinux
Loaded policy name:             strict
Current mode:                   enforcing
Mode from config file:          enforcing
Policy MLS status:              disabled
Policy deny_unknown status:     denied
Max kernel policy version:      26</programlisting>
      </section>

      <section>
        <title>grSecurity kernel improvements</title>

        <para>Next to the previously mentioned grSecurity updates, grSecurity
        also adds in additional kernel protection measures. This includes
        additional hardening on chroot jails (to make it a lot more difficult
        to break out of a chroot) and file system abuse (like getting
        information from pseudo-filesystems to improve attacks).</para>

        <para>For more information on enabling grSecurity, see the Gentoo
        grSecurity v2 Guide.</para>
      </section>
    </section>

    <section>
      <title>Installation choices</title>

      <para>During the initial installation of Gentoo, a few choices will
      already need to be made.</para>

      <section>
        <title>Partitioning and LVM</title>

        <para>In our architecture, we will be using directly attached storage
        (so no SAN nor NAS for every possible file system) and deal with the
        consequences of having distributed storage differently. One of the
        methods we will be using is to use LVM wherever we can, including for
        the root file system. I do recommend that the internal storage is
        somewhat protected against disk failure through RAID. Although I am a
        proponent of RAID1, <link
        xlink:href="http://assets.en.oreilly.com/1/event/27/Linux%20Filesystem%20Performance%20for%20Databases%20Presentation.pdf">tests</link>
        have shown that RAID5 performs equally well.</para>

        <para>We will use a non-LVM partition (RAID1 protected) for the /boot
        location, and use LVM volumes for the rest. We will also define
        different volume groups for system versus data.</para>

        <programlisting># <command>pvcreate /dev/md1</command>
# <command>vgcreate vg_system /dev/md1</command>
# <command>lvcreate -l 20G -n lv_root vg_system</command>
# <command>lvcreate -l 10G -n lv_home vg_system</command></programlisting>

        <para>Through this approach, the root file system will be hosted on
        /dev/mapper/vg_system-lv_root and as such be expandable (if necessary)
        as well as protected by the underlying RAID system. If you keep enough
        free space in the volume group, you can work with snapshots to support
        flexible backup methods.</para>

        <para>Needless to say, you will need to boot with an initramfs.</para>

        <programlisting># <command>genkernel --install --lvm initramfs</command></programlisting>

        <para>Don't forget to update the bootloader configuration.</para>
      </section>

      <section>
        <title>The /boot location</title>

        <para>I tend to keep my /boot location pretty "big" considering what
        other users think is needed: 1 Gbyte. Although the kernel and
        initramfs (plus boot loader files) are only a few megabytes, I often
        place a rescue environment in it (such as a <link
        xlink:href="http://www.sysresccd.org">sysresccd</link>) so that I can
        recover even when initramfs is unable to. It also allows me to install
        additional verification tools like memtest and the like.</para>
      </section>

      <section>
        <title>System logger</title>

        <para>For system logging, we will use syslog-ng, a well-supported
        advanced logging daemon.</para>

        <programlisting># <command>emerge syslog-ng</command></programlisting>
      </section>

      <section>
        <title>Network settings</title>

        <para>We will be using IPv6 exclusively in this architecture, but for
        some applications, we still need to support IPv4. When this is the
        case, we will try to only use 127.0.0.1.</para>

        <para>To setup a system with IPv6, first set the /etc/conf.d/net file
        accordingly. For instance, for one of our name servers (which we'll
        describe later):</para>

        <programlisting># <command>cat /etc/conf.d/net</command>
config_eth0="2001:db8:81:21::ac:98ad:5fe1/64";</programlisting>

        <para>Our hostname will be set in a fully qualified way (primarily for
        use by puppet later):</para>

        <programlisting># <command>cat /etc/conf.d/hostname</command>
hostname="ns.genfic.com"

# <command>cat /etc/hosts</command>
::1                             localhost
2001:db8:81:21::ac:98ad:5fe1  ns.genfic.com  ns</programlisting>

        <para>As a quick hint, if you want to ping hosts using IPv6, use
        <command>ping6</command>.</para>
      </section>
    </section>

    <section>
      <title>Generic architecture</title>

      <para>In the next graphic, you can see the generic architecture used for
      any Gentoo Linux deployment used further in this reference
      architecture.</para>

      <figure>
        <title>Generic architecture for Gentoo Linux deployments</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/02-gentoo.png"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>A bit of information on the used symbols might be in
      place...</para>

      <para>The parallellograms give information on particular use cases or
      activities involved with the architecture. To keep things simple, I am
      not going to make much differentiation in the notations between
      different types. The orange-colored blocks are specific components that
      are used, most of the time software titles (and sometimes drivers) that
      will be used to support particular functions or capabilities in the
      architecture.</para>

      <section>
        <title>Administration of the operating system</title>

        <para>Administration will be done through OpenSSH (for performing
        operational changes) and is shown by the activity
        <emphasis>ADMIN-SYSTEM</emphasis>. You can see that OpenSSH will also
        trigger an activity called <emphasis>AUTH-USER</emphasis>. This is
        because we will be using a central repository for authentication and
        authorization services (an OpenLDAP, which we will see later). The use
        of OpenSSH here is because it is the most obvious and well supported
        remote administration tool used for Unix and Linux around. The
        software also supports many additional features like X11 tunneling,
        advanced logging capabilities, and is also SELinux-aware.</para>

        <para>Mass changes will be triggered through
        <emphasis>CONFIG-SYSTEM</emphasis>, using Puppet. Puppet is a
        cross-platform, central configuration tool, where you define the state
        of the system (how it should be) and let Puppet decide how to change
        the system from the existing state to the "to-be" state. We will use
        Puppet to store the master configuration settings, and either have
        Puppet push the changes or use the Puppet configuration as master for
        further changes.</para>

        <para>When necessary, we will trigger a <emphasis>RESTORE</emphasis>
        of one or more files through the (TODO decide which one) backup
        solution.</para>
      </section>

      <section>
        <title>Outgoing connections</title>

        <para>By default, the system will have the following outgoing
        flows:</para>

        <itemizedlist>
          <listitem>
            <para><emphasis>SEND-LOG</emphasis> is the system logger sending
            out the system logs of the most important components (including
            audit entries) towards a central logging service to make sure that
            malicious cannot modify any log entries on the host they might
            have obtained (illegal) administrative rights</para>
          </listitem>

          <listitem>
            <para><emphasis>SEND-EVENT</emphasis> is the monitoring system
            (TODO decide which one) sending out availability and performance
            events towards the monitoring service.</para>
          </listitem>

          <listitem>
            <para><emphasis>SEND-MAIL</emphasis> is the local mail transport
            system sending out e-mails. These can originate from local running
            jobs or status changes that we configure sending mails for.</para>
          </listitem>

          <listitem>
            <para><emphasis>SEND-BACKUP</emphasis> is the feed of local backup
            data being sent out to the central backup repository.</para>
          </listitem>
        </itemizedlist>
      </section>
    </section>
  </section>

  <section>
    <title>Virtualization using Ganeti and KVM</title>

    <para>When possible, we will use virtualization. As virtualization
    platform, we will choose KVM as it offers many interesting features (both
    for development as well as larger enterprise usability) and is quite
    popular in the Linux development (and user) community. Other
    virtualization techniques that can be used are Xen or Virtualbox. Within
    Gentoo Linux however, KVM is most known.</para>

    <section>
      <title>Why virtualize</title>

      <para>Virtualization has been around for quite some time. Early
      mainframe installations already had a sort of isolation that is not far
      off from virtualization nowadays. However, virtualization is not just a
      mainframe concept anymore - most larger enterprises are already fully
      working on the virtualization of their stacks. Products like
      VMWare<indexterm>
          <primary>VMWare</primary>
        </indexterm> have popularized virtualization in the enterprise, and
      other hypervisors like KVM, VirtualBox, Xen and more are trying to get a
      piece of the cacke.</para>

      <para>To help administrators manage the virtual guests that are running
      on dozens of hosts, frameworks have emerged that lift some of the
      management tasks to a higher level. These frameworks offer automated
      generation of new guests, simplified configuration of the instances,
      remote management of guests. Some of them even support maintenance
      activities, such as moving guests from one host to another, or monitor
      the resource consumption of guests to find a good balance between
      running guests and available hosts.</para>

      <para>In Gentoo, many of these virtualization frameworks are
      supported.</para>

      <para>The first one is <package>app-emulation/libvirt</package> and is
      RedHat's virtualization management platform. The hypervisor systems run
      the libvirt daemon which manages the virtual guests as well as storage
      and other settings, and the administrator remotely connects to the
      various hypervisor systems through the
      <package>app-emulation/virt-manager</package> application. It has
      support for SELinux through its s(ecure)Virt(ualization) feature. To do
      so, it does require the MCS SELinux policy. Libvirt is also being used
      by many other frameworks (like oVirt, Archipel, Abiquo and more).</para>

      <para>Another one that is gaining momentum is
      <package>app-emulation/ganeti</package> and is backed by Google. It is
      foremost a command-line driven method but is well capable of handling
      dozens and dozens of hypervisor systems. It supports simplified
      fail-over on top of DRBD and makes an abstraction of the running hosts
      versus the guests. It bundles a set of hosts (which it calls nodes) in
      logical groups called clusters. The guests (instances) are then spread
      across the nodes in the cluster, and the administrator manages the
      cluster remotely.</para>

      <para>In this reference architecture, I will be using ganeti, but
      depending on how it works out, I might switch to the other later. The
      two (libvirt and ganeti) are equally strong, although libvirt has a much
      more active development community. On the other hand, Ganeti looks to be
      simpler in its design.</para>

      <para>Using virtualization has a whole set of advantages of which I'll
      try to mention a few in the next paragraphs. I will use the term
      <emphasis>host</emphasis> when talking about the host operating system
      (the one running or directly managing the hypervisor software) and
      <emphasis>guest</emphasis> for the virtualized operating system
      instances (that are running on the host).</para>

      <section>
        <title>High Availability</title>

        <para>In a virtualized environment, guests can be quickly restarted
        when needed. The host is still up and running, so rebooting a system
        is a matter of restarting a process. This has the advantage that
        caching and other performance measures taken by the hypervisor are
        still available, which makes bootup times of guests quite fast.</para>

        <para>But even in case of host downtime, given the right architecture,
        guests can be quickly started up again. By providing a hardware
        abstraction in the virtualization layer, these technologies are able
        to start a guest on a different hardware environment (even with
        different hardware, although there are limits to this - the most
        obvious one being that the new hardware must support the same
        architecture and virtualization). Many virtualization solutions can
        host guest storage (the guests' disks) in image files which can be
        made highly available through high-performance NFS shares, cluster
        filesystem or storage synchronisation. If the host crashes, the guest
        storage is quickly made available on a different host and the guest is
        restarted.</para>
      </section>

      <section>
        <title>Resource optimization</title>

        <para>For most organizations, virtualization is one of the most
        effective ways to optimize resources in their data rooms. Regular
        Unix/Windows servers generally consume lots of power, cooling and
        floor space while still only offering 15% (or less) of actual resource
        consumption (CPU cycles). 85% of the time, the system is literally
        doing nothing but waiting. With virtualization, you can have resources
        utilized better, going towards a healthy 80% while still allowing room
        for sudden resource burst demands.</para>
      </section>

      <section>
        <title>Flexible change management</title>

        <para>The virtualization layer also offers a way to do flexible change
        management. Because guests are now more tangible, it is easier to make
        snapshots of entire guests, copy them around, upgrade one instance
        and, if necessary, roll back to the previous snapshot - all this in
        just a few minutes or less. You can't do this with dedicated
        installations.</para>
      </section>

      <section>
        <title>"Secure" isolation</title>

        <para>In a security-sensitive environment, isolation is a very
        important concept. It ensures that a system or service can only access
        those resources it needs to, while disallowing (and even hiding) the
        other resources. Virtualization allows architects to design the system
        so that it runs in its own operating system, so from the viewpoint of
        the service, it has access to those resources it needs, but sees no
        other. On the host layer, the guests can then be properly isolated so
        they cannot influence each other.</para>

        <para>Having separate operating systems is often seen as a thorough
        implementation of "isolation". Yes, there are a lot of other means to
        isolate services. Still, running a service in a virtualized operating
        system is not the summum of isolation. <link
        xlink:href="http://blog.nelhage.com/2011/08/breaking-out-of-kvm/">Breaking
        out of KVM</link> has been done in the past, and will most likely
        happen again. Other virtualization have seen their share of security
        vulnerabilities to this level as well.</para>
      </section>

      <section>
        <title>Simplified backup/restore</title>

        <para>For many organizations, a bare-metal backup/restore routine is
        much more resource hungry than regular file-based backup/restore. By
        using virtualization, bare-metal backup/restore of the guests is a
        breeze, as it is now back a matter of working with files (and
        processes). Ok, the name "bare-metal" might not work anymore here -
        and you'll still need to backup your hypervisor. But if your
        hypervisor (host) installation is very standardized, this is much
        faster and easier than before.</para>
      </section>

      <section>
        <title>Fast deployment</title>

        <para>By leveraging the use of guest images, it is easy to create a
        single image and then use it as a master template for other instances.
        Need a web serving cluster? Set up on, replicate and boot. Need a few
        more during high load? Replicate and boot a few more. It becomes just
        that easy.</para>
      </section>
    </section>

    <section>
      <title>Ganeti and KVM</title>

      <para>In this reference architecture, we will be using KVM as the
      hypervisor software, and Ganeti as the management software that allows
      us to manage the instances running on multiple systems. High-level, we
      will be using Ganeti as described in the next figure.</para>

      <figure>
        <title>General Ganeti architecture</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/02-ganeti.png"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Within Ganeti, we will define a cluster that has a number of
      nodes. Per cluster, we will keep the number of nodes manageble (although
      the figure shows just two nodes, we aim for a cluster of about 12 nodes
      each). Within the cluster, one or more instances can be defined as being
      "highly available", which means that they will use DRBD storage
      synchronisation towards a second node. In case of failure, those
      instances can then be restarted on this secundary system.</para>

      <figure>
        <title>Fail over of high available instance</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="images/02-ganeti2.png"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Instances that are not defined as highly available (like "Instance
      1" in the drawings) cannot be easily restarted on a secundary
      system.</para>

      <section>
        <title>All the virtualization advantages</title>

        <para>The use of Ganeti and KVM offers us with all the virtualization
        advantages mentioned before...</para>

        <itemizedlist>
          <listitem>
            <para>By using DRBD (which is a network-based disk replication
            feature of Linux) we can offer high available hosts which are
            capable of quickly starting up guests if the primary system
            fails.</para>
          </listitem>

          <listitem>
            <para>Because we will use LVM with DRBD, we can support
            snapshotting to simplify backup and restore routines, or even
            change management activities that have a higher risk associated
            with them.</para>
          </listitem>

          <listitem>
            <para>Ganeti offers cluster rebalancing, making it easier to
            optimize resource consumption across the cluster (Ganeti calls a
            combination of nodes, which run a given set of guests, a
            cluster).</para>
          </listitem>

          <listitem>
            <para>With the help of some simple scripts, Ganeti allows us to
            quickly add more instances, using other images as master.</para>
          </listitem>
        </itemizedlist>
      </section>

      <section>
        <title>Hypervisor kernel configuration</title>

        <para>A hypervisor<indexterm>
            <primary>hypervisor</primary>
          </indexterm> is the general term given to the host operating system
        that offers virtualization services, so in effect is running the
        virtual guests as processes (or groups of processes). In case of
        KVM<indexterm>
            <primary>KVM</primary>
          </indexterm>, this means that the Linux kernel will be configured
        with KVM enabled (and with the proper virtualization improvements on
        various drivers) as well as userland utilities to support KVM
        guests.</para>

        <para>Below you can find a subset of kernel configuration settings
        that can be used as a base for the configuration:</para>

        <programlisting># <command>zgrep -E '(KVM|VIRT)' /proc/config.gz</command>
# CONFIG_PARAVIRT_GUEST is not set
CONFIG_VIRT_TO_BUS=y
CONFIG_VIRTIO_BLK=m
CONFIG_VIRTIO_NET=m
# CONFIG_VIRTIO_CONSOLE is not set
# CONFIG_HW_RANDOM_VIRTIO is not set
# CONFIG_FB_VIRTUAL is not set
# CONFIG_SND_VIRTUOSO is not set
CONFIG_VIRTIO=m
CONFIG_VIRTIO_RING=m
# CONFIG_VIRTIO_PCI is not set
CONFIG_VIRTIO_BALLOON=m
CONFIG_VIRT_DRIVERS=y
# CONFIG_DEBUG_VIRTUAL is not set
CONFIG_GRKERNSEC_HARDENED_VIRTUALIZATION=y
CONFIG_HAVE_KVM=y
CONFIG_HAVE_KVM_IRQCHIP=y
CONFIG_HAVE_KVM_EVENTFD=y
CONFIG_KVM_APIC_ARCHITECTURE=y
CONFIG_KVM_MMIO=y
CONFIG_KVM_ASYNC_PF=y
CONFIG_VIRTUALIZATION=y
CONFIG_KVM=m
CONFIG_KVM_INTEL=m
# CONFIG_KVM_AMD is not set</programlisting>

        <para>Make sure that your hardware systems support hardware-assisted
        virtualization. For Intel processors, this means that vmx must be
        available; on AMD processors, this is svm:</para>

        <programlisting># <command>egrep '(vmx|svm)' /proc/cpuinfo | head -1</command>
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat \
                  pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx \
                  rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl \
                  xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl <emphasis>vmx</emphasis> \
                  est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm ida \
                  arat dts tpr_shadow vnmi flexpriority ept vpid</programlisting>

        <para>Because we are aiming for a hypervisor kernel, it is best to
        remove all drivers not needed by the host. I am not directly opposed
        to using kernel modules versus a monolithic kernel, but if the
        configuration allows it, my preference goes to monolithic builds. This
        also has the advantage that the initramfs does not need to take care
        of kernel module loading.</para>
      </section>

      <section>
        <title>Installing KVM Utilities</title>

        <para>To build up the hypervisor, you first need to install
        qemu-kvm<indexterm>
            <primary>qemu-kvm</primary>
          </indexterm>. This is the base platform under which the guests will
        run and supports all possible features you need in a virtualized
        environment.</para>

        <programlisting># <command>emerge qemu-kvm</command></programlisting>

        <para>The package listens to a lot of USE flags. Many of those are
        however to enable support for other architectures (as QEMU is a
        software virtualization platform which you can use even without
        hardware virtualization assistance). My advise is to at least enable
        aoi (Asynchronous I/O support), sasl (Simple Authentication and
        Security Layer support), threads, vde (Virtual Distributed Ethernet
        support) and vhost-net.</para>

        <para>The qemu-kvm package already provides command-line utilities
        that you can use to create image files, launch guests, set up
        networking etc. However, these commands are quite complex and,
        especially for distributed environments, difficult to manage...</para>

        <programlisting># <command>qemu-system-x86_64 --enable-kvm -gdb tcp::1237 -vnc 127.0.0.1:3 \
     -net nic,model=virtio,macaddr=00:11:22:33:44:b1,vlan=0 \
     -net vde,vlan=0 -drive file=/srv/virt/gentoo/test.img,if=virtio,boot=on \
     -usb -usbdevice tablet -smp 4 -cpu kvm64 -k nl-be -m 1536</command></programlisting>
      </section>

      <section>
        <title>Installing ganeti</title>

        <para>The installation of ganeti is quite simple: install ganeti and
        ganeti-htools. If you are planning on providing a high-available
        virtualization platform, install drbd as well.</para>

        <programlisting># <command>emerge ganeti ganeti-htools drbd</command></programlisting>
      </section>
    </section>

    <section>
      <title>Using Ganeti</title>

      <section>
        <title>Architectural information</title>

        <para>There are a few things you need to know before starting off with
        Ganeti, especially in light of architecturing its use.</para>

        <itemizedlist>
          <listitem>
            <para>Ganeti uses SSH and specific TCP (over SSL) connections. The
            use of SSH here might be something worth knowing, since it is used
            to support remote root activities on the nodes. You might want to
            take additional precautions to protect abuse of remote root
            logons. In the future, I will be providing a SELinux user specific
            for ganeti, and have remote root logons automatically assigned to
            this user, so it remains confined. There is also a <link
            xlink:href="https://code.google.com/p/ganeti/issues/detail?id=197">patch</link>
            circulating on the Internet that would support non-root
            logons.</para>
          </listitem>

          <listitem>
            <para>The use of DRBD (for replication) within Ganeti is best kept
            for synchronisation within a single network segment (so "local"
            high availability). It is not the intention to use this across
            larger distances. DRBD by itself can still be used for that, but
            not in combination with booting the guest images. This is
            partially because the guest images will expect the same network
            environment when they boot up as previous.</para>

            <para>In our reference architecture, we will be using application
            fail-over when large-distance high availability is
            necessary.</para>
          </listitem>
        </itemizedlist>

        <figure>
          <title>High-level Ganeti host architecture</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="images/02-kvmops.png"/>
            </imageobject>
          </mediaobject>
        </figure>

        <para>A ganeti node will be managed through the regular management
        channels like OpenSSH and Puppet, just as described earlier. In the
        above drawing, we make a bit of differentiation on the interfaces
        through which traffic will flow</para>

        <itemizedlist>
          <listitem>
            <para><emphasis>SERVICE-LAN</emphasis> is the operational
            (business) service activities, both for the instances themselves
            (which will be aggregated through a bridge interface) as well as
            the ganeti node.</para>
          </listitem>

          <listitem>
            <para><emphasis>MGMT-LAN</emphasis> is for management activities
            as described earlier</para>
          </listitem>

          <listitem>
            <para><emphasis>DRBD-SYNC</emphasis> is one of the back-end
            specific data flows (others, such as logging output, have been
            described earlier) for this particular description.</para>
          </listitem>
        </itemizedlist>

        <para>By properly segregating the service flows (which are SLA bound)
        from the administrative ones (which should be limited to known
        changes) and back-end (which are expected to be more heavy but better
        manageable, perhaps using QoS) we should be able to provide good
        monitoring on the used services, improve management and bandwidth
        usage and perhaps even improve security without losing or hindering
        administrators and engineers in their day-to-day tasks.</para>
      </section>

      <section>
        <title>Preparing DRBD</title>

        <para>Because high available virtual guests will be used in this
        reference architecture, we will be configuring DRBD.</para>

        <para>DRBD<indexterm>
            <primary>DRBD</primary>
          </indexterm> uses the network to synchronise block devices. It is
        adviseable to have a different network for this back-end communication
        versus the network used for front-end (business) activity. Logically
        speaking, we will have 3 network channels: one for the data flow of
        the services, one for the management activities and one for the
        back-end synchronisation. You can have all these channels on a single
        Ethernet if you want, but logically speaking, they are
        separate.</para>

        <para>In our architecture, we will be putting DRBD on top of LVM, and
        then use LVM again based on DRBD devices. This stacking of
        technologies has the downside of some complexity (and perhaps even
        performance impact) but has advantages that imo win against the
        downsides.</para>

        <itemizedlist>
          <listitem>
            <para>Because DRBD works on top of LVM, you can expand the size of
            the underlying LVM volume groups and logical volumes. DRBD
            supports on-line resizing.</para>
          </listitem>

          <listitem>
            <para>Because DRBD works on top of LVM, you can use LVM snapshot
            technology to provide better resilience against failures.
            Especially during synchronisation, if the source fails and the
            target is in an inconsistent state, you will be glad to have a
            snapshot (on the receiving side) to work from.</para>
          </listitem>

          <listitem>
            <para>Because LVM works on top of DRBD, you have the advantages of
            the volume manager for your image management functions while still
            benefiting from the high availability mode that DRBD
            offers.</para>
          </listitem>
        </itemizedlist>

        <para>In the near future, I might include clustering file systems as
        well. However, for now, I am less convinced about the maturity of
        these file systems whereas I have read good reviews (and specifically
        many) on DRBD in production scenarios.</para>

        <para>To properly have DRBD for Ganeti, it is mandatory to run it with
        the following two options. The listing shows them as kernel
        parameters, but you can use them as module parameters as well (in
        /etc/conf.d/modules):</para>

        <programlisting>drbd.minor_count=255 drbd.usermode_helper=/bin/true</programlisting>

        <para>We also need to protect the DRBD devices from being scanned by
        LVM. To accomplish this, edit /etc/lvm/lvm.conf as follows:</para>

        <programlisting>filter = [ "r|/dev/nbd.*|", "a/.*/"<emphasis>, "r|/dev/drbd[0-9]+|"</emphasis> ]</programlisting>

        <para>Finally edit /etc/drbd.conf and skip all existing resource
        configurations. Ganeti will configure DRBD itself when needed.</para>

        <programlisting># <command>cat /etc/drbd.conf</command>
<emphasis>skip</emphasis> resource r0 {
  ...
}</programlisting>
      </section>

      <section>
        <title>Preparing Ganeti</title>

        <para>Make sure that the hostname setting in
        <filename>/etc/conf.d/hostname</filename> provides a fully qualified
        hostname. Ganeti will otherwise refuse to function properly.</para>

        <programlisting># <command>cat /etc/conf.d/hostname</command>
## Ganeti Cluster 01 Node 01 in production hosts.genfic.com network
hostname="gc01n01.hosts.genfic.com"</programlisting>

        <para>Next prepare the LVM volume group you will use to host the guest
        images on.</para>

        <programlisting># <command>pvcreate /dev/md2</command>
# <command>vgcreate vg_ganeti /dev/md2</command></programlisting>
      </section>

      <section>
        <title>Creating the first cluster</title>

        <para>Now we can initialize the first cluster (and node).</para>

        <programlisting># <command>gnt-cluster init --master-netdev=br0 -g vg_ganeti -s &lt;node drbd_ip&gt; \
   --enabled-hypervisors=kvm -N link=br0 -B vcpus=2,memory=512 \
   -H kvm:kernel_path=/srv/virt/vmlinuz gc01n01.virt.internal.genfic.com</command></programlisting>
      </section>

      <section>
        <title>Expanding the cluster</title>

        <para>When you have configured a second system, instead of
        initializing a cluster, you use:</para>

        <programlisting># <command>gnt-cluster add -s &lt;node drbd_ip&gt; &lt;node hostname&gt;</command></programlisting>
      </section>
    </section>
  </section>

  <section>
    <title>Resources</title>

    <para>For more information about the topics in this chapter, you can
    divulge yourself in the information available at the following
    resources...</para>

    <para>Gentoo Hardened:</para>

    <itemizedlist>
      <listitem>
        <para><link
        xlink:href="http://www.gentoo.org/proj/en/hardened/pax-quickstart.xml">Hardened
        Gentoo PaX Quickstart</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link xlink:href="http://hardened.gentoo.org">Gentoo Hardened
        project page</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://eli.thegreenplace.net/2011/11/03/position-independent-code-pic-in-shared-libraries/">Position
        Independent Code</link> in shared libraries</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://www.gentoo.org/proj/en/hardened/pic-guide.xml">Introduction
        to Position Independent Code</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://blog.fpmurphy.com/2008/06/position-independent-executables.html">Position
        Independent Executables</link></para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://www.gentoo.org/proj/en/hardened/selinux/selinux-handbook.xml">Gentoo
        SELinux Handbook</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://www.gentoo.org/proj/en/hardened/grsecurity.xml">Gentoo
        grSecurity v2 Guide</link> (Gentoo Linux)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://dev.gentoo.org/~swift/docs/security_benchmarks/">Security
        benchmarks</link></para>
      </listitem>
    </itemizedlist>

    <para>KVM virtualization &amp; Ganeti:</para>

    <itemizedlist>
      <listitem>
        <para><link xlink:href="http://www.lancealbertson.com/">Lance
        Albertson's blog</link> (high focus on Ganeti and Gentoo)</para>
      </listitem>

      <listitem>
        <para><link
        xlink:href="http://docs.ganeti.org/ganeti/current/html/">Ganeti
        documentation</link></para>
      </listitem>

      <listitem>
        <para><link xlink:href="http://notes.ceondo.com/ganeti/">Ganeti
        deployment notes</link> (Céondo)</para>
      </listitem>
    </itemizedlist>
  </section>
</chapter>
